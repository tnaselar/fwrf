{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit test the fwrf model and all it's parts'\n",
    "Expected dimensions\n",
    "inputs --> T,D,S,S  \n",
    "rf layer output --> T,D,V  \n",
    "norm_layer --> T,D,V  \n",
    "activation_layer --> T,D,V  \n",
    "feature_weights_layer --> T,V  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 256 ##trials\n",
    "D = [61, 62, 63] ##features\n",
    "S = [11, 12, 13]\n",
    "nmaps = len(D)\n",
    "map_names = sting.uppercase[:nmaps]\n",
    "V = 100 ##voxels\n",
    "deg_per_stim = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MakeSpaceTest(unittest.TestCase):\n",
    "    def test_make_space(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class fwrfTest(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        \n",
    "        #testing of individual layers done with first feature map\n",
    "        #testing of rf_model_space and fwrf done with full feature map dict.\n",
    "        \n",
    "        #--feature maps\n",
    "        self.feature_map_dict = {key: val for key,val in zip(map_names, [np.random.rand(T,D[ii],S[ii],S[ii]) for ii in range(nmaps)])}\n",
    "        self.means = [np.mean(self.feature_map_dict[key],axis=0) for key in self.feature_map_dict.keys()]\n",
    "        self.stds = [np.std(self.feature_map_dict[key],axis=0) for key in self.feature_map_dict.keys()]\n",
    "        \n",
    "        #--input\n",
    "        self.input_shape = (T,D,S[0],S[0])\n",
    "        #this tensor stores feature map\n",
    "        self.f_map_0 = tnsr.tensor4('f_map_0',dtype='float32')  \n",
    "        #the lasagne input layer\n",
    "        self.layer_1 = lasagne.layers.InputLayer(self.input_shape, input_var = self.f_map_0, name='layer_1')\n",
    "        \n",
    "        #--rf layer\n",
    "        self.rf_layer = receptive_field_layer(self.layer_1, V, make_space(S[0]), deg_per_stim, name='rf_layer')\n",
    "        \n",
    "        #--activation layber\n",
    "        self.act_layer = compressive_nonlinearity_layer(self.rf_layer,name='act_layer')\n",
    "        \n",
    "        #--norm layer\n",
    "        self.norm_layer = normalization_layer(self.act_layer, )\n",
    "        \n",
    "    \n",
    "    def tearDown(self):\n",
    "        pass\n",
    "    \n",
    "    def test_param_get_set(self):\n",
    "        pass\n",
    "    \n",
    "    def test_rf_layer(self):\n",
    "        pass\n",
    "    \n",
    "    def test_norm_layer(self):\n",
    "        pass\n",
    "    \n",
    "    def test_modelspace(self):\n",
    "        pass\n",
    "    \n",
    "    def test_feature_weights_layer(self):\n",
    "        pass\n",
    "    \n",
    "    def test_fwrf_init(self):\n",
    "        pass\n",
    "    \n",
    "    def test_learn_lasagne_model(self):\n",
    "        pass\n",
    "    \n",
    "    def test_fwrf_train_me_coarse(self):\n",
    "        pass\n",
    "    \n",
    "    def test_fwrf_train_me_fine(self):\n",
    "        pass\n",
    "    \n",
    "    def test_fwrf_decode(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
