{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lasagne\n",
    "import matplotlib.pyplot as plt\n",
    "from theano import tensor as tnsr\n",
    "from theano import function\n",
    "from theano import map as tmap\n",
    "from theano import shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class batch_feature_map_decoder(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 init_feature_maps,\n",
    "                 trn_model, val_model,\n",
    "                 trn_model_input_tnsr_dict, val_model_input_tnsr_dict,\n",
    "                 trn_data, val_data,\n",
    "                 epochs = 1,\n",
    "                 check_every=10,\n",
    "                 num_iters=10,\n",
    "                 learning_rate = 1.0,\n",
    "                 learn_these_feature_maps = None,\n",
    "                 is_movie = False,\n",
    "                 check_dims = True,\n",
    "                 print_stuff=False):\n",
    "\n",
    "        '''\n",
    "    batch_feature_map_decoder(   init_feature_maps,\n",
    "                                 trn_model, val_model,\n",
    "                                 trn_model_input_tnsr_dict, trn_model_input_tnsr_dict,\n",
    "                                 trn_data, val_data,\n",
    "                                 epochs = 1,\n",
    "                                 check_every=10,\n",
    "                                 num_iters=10,\n",
    "                                 learning_rate = 1.0,\n",
    "                                 learn_these_feature_maps = None,\n",
    "                                 is_movie = False,\n",
    "                                 check_dims = True,\n",
    "                                 print_stuff=False)\n",
    "\n",
    "        a class for gradient descent on independent feature maps, given encoding models and activity patterns.\n",
    "\n",
    "        inputs:\n",
    "                init_feature_maps   ~ dict map_name/tensor pairs. \n",
    "                                      tensors have shape (T,D,S,S), where T is temporal length of stimulus.\n",
    "                                      for stacks of T static images, optimization is performed independently\n",
    "                                      for each image.\n",
    "                                      for movies of T frames, we assume we have model weights that have a temporal\n",
    "                                      dimension, so optimization will be for entire movie (i.e., frames not indepen't.)\n",
    "                trn_model,val_model ~ lasagne models\n",
    "   trn_/val_model_input_tensor_dict ~ dicts of theano tensors that are inputs to trn/val_model, resp.\n",
    "                           trn_data ~ tensor of voxel activity, shape=(num_stimuli, T, num_trn_voxels)\n",
    "                           val_data ~ tensor of voxel activity, shape=(num_stimuli, T, num_val_voxels)\n",
    "                        check_every ~ int. how many gradients steps until validation loss is checked. default = 10\n",
    "                          num_iters ~ number of gradient steps per batch before tranistioning to next batch. default = 100\n",
    "                      learning_rate ~ size of gradient step. default = 1\n",
    "           learn_these_feature_maps ~ list of names of feature maps to learn. \n",
    "                                      default = None, meaning learn all feature maps\n",
    "                           is_movie ~ encoding model includes temporal kernel, so that output at any one point\n",
    "                                      depends on many of the T frames, set this to True. Otherwise, will treat each\n",
    "                                      of the T time-points as independent frames and optimize them separately.\n",
    "                         check_dims ~ if True, run potentially slow sanity check on dimensions of inputs\n",
    "        outputs:\n",
    "        decoded_feature_maps ~ original l_model with params all trained up. this is a convenience, as params are learned in-place\n",
    "              final_val_loss ~ the final validation loss for each of the models\n",
    "                 trn_history ~ array showing training err history\n",
    "                 val_history ~ history showing number of voxels with decreased validat'n loss at each iteration\n",
    "\n",
    "        '''\n",
    "        \n",
    "        ##record all the inputs\n",
    "        self.init_feature_maps = init_feature_maps\n",
    "        self.trn_model = trn_model\n",
    "        self.val_model = val_model\n",
    "        self.learn_these_feature_maps = learn_these_feature_maps\n",
    "        self.is_movie = is_movie\n",
    "        self.trn_model_input_tnsr_dict = trn_model_input_tnsr_dict\n",
    "        self.val_model_input_tnsr_dict = val_model_input_tnsr_dict\n",
    "        self.trn_data = trn_data\n",
    "        self.val_data = val_data\n",
    "        self.epochs = epochs\n",
    "        self.check_every=check_every\n",
    "        self.num_iters = num_iters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.print_stuff = print_stuff\n",
    "        self.check_dims = check_dims\n",
    "\n",
    "        ##inspect one batch of input to sanity check dimensions\n",
    "        if self.check_dims:\n",
    "            ##check data dimensions\n",
    "            self.check_consistent()\n",
    "    \n",
    "        ##get learned feature maps: stores as a list of shared variables just like output of lasage.layers.get_all_params\n",
    "        self.get_learned_maps()\n",
    "        \n",
    "        ##construct a gradient update and loss functions to be called iteratively by the learn method\n",
    "        self.decoding_kernel = self.construct_decoding_kernel()\n",
    "\n",
    "\n",
    "    def check_consistent( self ):\n",
    "        ##read first batches to get some dimensions. assumes first dimension of input is time, last dimension is voxel \n",
    "        num_trn_images,trn_batch_size = self.trn_data.shape[0],self.trn_data.shape[-1]\n",
    "        num_val_images,val_batch_size = self.val_data.shape[0],self.val_data.shape[-1]   \n",
    "        assert num_trn_images == num_val_images, \"number of trn/val images don't match\"\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def get_learned_maps( self ):\n",
    "        '''\n",
    "        NOTE: Should probably establish learned_maps as shared variables?\n",
    "        return list of theano variables\n",
    "        '''\n",
    "        if self.learn_these_feature_maps is not None:            \n",
    "            self.learned_maps = [v for v in self.trn_model_input_tnsr_dict.values() if v.name in self.learn_these_feature_maps] ##<<unpack the dict.\n",
    "        else:\n",
    "            self.learned_maps = [v for v in self.trn_model_input_tnsr_dict.values()] ##<<unpack the dict.\n",
    "        print 'will solve for: %s' %(self.learned_maps)\n",
    "\n",
    "\n",
    "                \n",
    "    ##construct a gradient update and loss functions to be called iteratively by the learn method\n",
    "    def construct_decoding_kernel( self ):\n",
    "        \n",
    "        if self.is_movie:\n",
    "            raise NotImplementedError('movies are not implemented yet.')\n",
    "        \n",
    "        ##===express training error\n",
    "        trn_activity_tensor = tnsr.matrix('trn_activity')\n",
    "        \n",
    "        trn_pred_expr = lasagne.layers.get_output(self.trn_model)\n",
    "\n",
    "        trn_diff = trn_activity_tensor-trn_pred_expr  ##difference tensor: (T x V)\n",
    "        \n",
    "        ##first sum over voxels, then over time-points\n",
    "        trn_loss_expr = (trn_diff*trn_diff).sum(axis=1).sum()\n",
    "\n",
    "        ##Training loss is scalar because of sum() on the trn_loss_expr: this is a sum over T dimension\n",
    "        self.trn_loss_func = function([trn_activity_tensor]+self.trn_model_input_tnsr_dict.values(), trn_loss_expr)\n",
    "\n",
    "        ##===express validation error\n",
    "        val_activity_tensor = tnsr.matrix('val_activity')\n",
    "        val_pred_expr = lasagne.layers.get_output(self.val_model)\n",
    "        val_diff = val_activity_tensor-val_pred_expr  ##difference tensor: (T x V)\n",
    "        val_loss_expr = (val_diff*val_diff).sum(axis=1) ##sum-sqaured-diffs tensor: SUM OVER VOXELS\n",
    "\n",
    "        ##Validation loss has T distinct outputs, not scalar.\n",
    "        ##self.loss(activity_matrix, fmap0, ... , fmapN)\n",
    "        self.loss = function([val_activity_tensor]+self.val_model_input_tnsr_dict.values(), val_loss_expr)\n",
    "\n",
    "        ##===build gradient w.r.t. input vars\n",
    "        grad_expr = tnsr.grad(trn_loss_expr, wrt=self.learned_maps)\n",
    "\n",
    "        ##a list of feature map gradients.\n",
    "        ##each gradient in the list should be like T,D,S,S tensor4\n",
    "        print 'compiling...'\n",
    "        grad_func = function([trn_activity_tensor]+self.trn_model_input_tnsr_dict.values(), grad_expr)\n",
    "        \n",
    "        ##closure\n",
    "        def decoding_kernel():\n",
    "            args = [self.trn_data]+self.init_feature_maps.values()\n",
    "            map_grads = grad_func(*args)\n",
    "            ##update each feature map using names of theano variables ininput_var_dict\n",
    "            ##note: we can enumerate because dict.values() and dict.keys() has same order...I think...\n",
    "            ##note: probably a way we can vectorize this.\n",
    "            for ii,k in enumerate(self.learned_maps.keys()):\n",
    "                ##We assume (hope!) that \n",
    "                self.init_feature_maps[k] -= learning_rate*map_grads[ii]\n",
    "            return self.trn_loss_func(self.trn_data,*self.init_feature_maps.values())\n",
    "        \n",
    "        return decoding_kernel\n",
    "        \n",
    "        \n",
    "    ##if the last gradient step made things better for some the time-points, update the feature maps for that time-point\n",
    "    def update_best_time_points(self, best_fmap_dict, improved_time_points):\n",
    "        \n",
    "        ##this implicitly checks for consistency between keys of learned maps, init_feature_maps, and best_fmap_dict\n",
    "        for k in self.learned_maps.keys():\n",
    "            ##this indexing should work because time points is always the first dimension\n",
    "            best_fmap_dict[k][improved_time_points] = np.copy(self.init_feature_maps[k][improved_time_points])\n",
    "        return best_fmap_dict        \n",
    "    \n",
    "    ##iteratively perform gradient descent\n",
    "    def learn(self):\n",
    "        \n",
    "        ##initialize best parameters to whatever they are\n",
    "        best_fmap_dict = {k:np.copy(v) for k,v in self.init_feature_maps.iteritem()}\n",
    "        \n",
    "        ##initalize validation loss to whatever you get from initial fmaps\n",
    "        val_loss_was = self.loss(val_data, *best_fmap_dict.values())\n",
    "\n",
    "        ##initialize train loss to whatever, we only report the difference    \n",
    "        trn_loss_was = 0.0 ##we keep track of total across voxels as sanity check, since it *must* decrease\n",
    "  \n",
    "        val_history = []\n",
    "        trn_history = []\n",
    "        \n",
    "        ##descend and validate\n",
    "        step_count = 0\n",
    "        while step_count < self.num_iters:\n",
    "            \n",
    "            ##update fmaps, output training loss\n",
    "            trn_loss_is = self.decoding_kernel(trn_data, self.init_feature_maps.values())                    \n",
    "            if step_count % self.check_every == 0:\n",
    "\n",
    "                ##check for improvements\n",
    "                val_loss_is = 0\n",
    "                val_loss_is = self.loss(val_data, *self.init_feature_maps.values())\n",
    "                improved = (val_loss_is < val_loss_was) ##improved ~ (T,)\n",
    "\n",
    "                ##update val loss\n",
    "                val_loss_was[improved] = val_loss_is[improved]\n",
    "\n",
    "                ##update best feature maps\n",
    "                best_fmap_values = self.update_best_time_points(best_fmap_dict, improved)\n",
    "\n",
    "                ##report on loss history\n",
    "                val_history.append(improved.sum())\n",
    "                trn_history.append(trn_loss_is)\n",
    "                if self.print_stuff:\n",
    "                    print '====iter: %d' %(step_count)\n",
    "                    print 'number of improved models: %d' %(val_history[-1])\n",
    "                    print 'trn error: %0.6f' %(trn_history[-1])\n",
    "\n",
    "            step_count += 1       \n",
    "\n",
    "        return best_fmap_dict, val_loss_was, val_history, trn_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will solve for: [input_tnsr]\n",
      "compiling...\n"
     ]
    }
   ],
   "source": [
    "##construct models\n",
    "T,D,S,Vtrn,Vval = 11,17,12,44,22\n",
    "\n",
    "input_tnsr = tnsr.tensor4('input_tnsr')\n",
    "input_layer = lasagne.layers.InputLayer((T,D,S,S),input_var=input_tnsr)\n",
    "\n",
    "true_feature_map = {'fmap':np.random.random(size=(T,D,S,S)).astype('float32')}\n",
    "init_feature_map = {'fmap':np.random.random(size=(T,D,S,S)).astype('float32')}\n",
    "\n",
    "trn_model = lasagne.layers.DenseLayer(input_layer,Vtrn)\n",
    "val_model = lasagne.layers.DenseLayer(input_layer,Vval)\n",
    "\n",
    "true_trn_activity = function([input_tnsr],lasagne.layers.get_output(trn_model))(true_feature_map['fmap'])\n",
    "true_val_activity = function([input_tnsr],lasagne.layers.get_output(val_model))(true_feature_map['fmap'])\n",
    "\n",
    "trn_model_input_tnsr_dict = {'fmap':input_tnsr}\n",
    "val_model_input_tnsr_dict = {'fmap':input_tnsr}\n",
    "trn_data = np.random.random(size=(T,Vtrn)).astype('float32')\n",
    "val_data = np.random.random(size=(T,Vval)).astype('float32')\n",
    "epochs = 1,\n",
    "check_every=10,\n",
    "num_iters=10,\n",
    "learning_rate = 1.0,\n",
    "learn_these_feature_maps = None,\n",
    "is_movie = False,\n",
    "check_dims = True,\n",
    "print_stuff=False\n",
    "\n",
    "decoder = batch_feature_map_decoder(init_feature_map,trn_model,val_model,trn_model_input_tnsr_dict,val_model_input_tnsr_dict,trn_data,val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##test val loss\n",
    "L = decoder.loss(true_val_activity,*true_feature_map.values())\n",
    "assert L.shape[0]==T, 'wrong bitch, shape is %d, not %d' %(L.shape[0], T)\n",
    "\n",
    "##test trn loss\n",
    "assert decoder.trn_loss_func(true_trn_activity,*true_feature_map.values())==0, 'wrong bitch!'\n",
    "assert decoder.trn_loss_func(true_trn_activity,*init_feature_map.values())!=0, 'wrong bitch!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-5a5c346a5215>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m##test decoding kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoding_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-70-6c09c57ce2b8>\u001b[0m in \u001b[0;36mdecoding_kernel\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;31m##note: we can enumerate because dict.values() and dict.keys() has same order...I think...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;31m##note: probably a way we can vectorize this.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearned_maps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m                 \u001b[1;31m##We assume (hope!) that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_feature_maps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap_grads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "##test decoding kernel\n",
    "print decoder.decoding_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
